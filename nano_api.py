import io
import requests
import json
import base64
import re
import os
import os.path as osp
import datetime
from typing import Optional, Tuple
from PIL import Image
from io import BytesIO
from tqdm import tqdm
# from api_class.utils import base64_to_image,encode_pil_to_base64
def encode_pil_to_base64(image_pil):
    # å°†PILå›¾åƒç¼–ç ä¸ºbase64å­—ç¬¦ä¸²
    buffered = BytesIO()
    image_pil.save(buffered, format="PNG")
    img_bytes = buffered.getvalue()
    img_base64 = base64.b64encode(img_bytes).decode('utf-8')
    mime_type = "image/png"
    return img_base64, mime_type

def base64_to_image(base64_str):
    # å°†base64å­—ç¬¦ä¸²è§£ç ä¸ºPILå›¾åƒ
    img_bytes = base64.b64decode(base64_str)
    image_pil = Image.open(BytesIO(img_bytes))
    return image_pil
class GeminiImageGenerator:
    def __init__(self,  api_url: str = "https://api.apiyi.com/v1beta/models/gemini-3-pro-image-preview:generateContent"):
        self.api_key = "sk-MC5B3H948s5YhiVN591f578fC74a4eC484659cC6005bB603"
        self.api_url = api_url
        self.api_url_compre="https://api.apiyi.com/v1/chat/completions"
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        self.SUPPORTED_ASPECT_RATIOS = [
        "21:9", "16:9", "4:3", "3:2", "1:1",
        "9:16", "3:4", "2:3", "5:4", "4:5"]
        
        self.SUPPORTED_RESOLUTION=["1K","2K","4K"]

    def nano_imageEditing(self,data_dict):
        required_keys = {"prompt","image_list","ratio","resolution"}
        assert required_keys <= data_dict.keys(), \
            f"ç¼ºå°‘å¿…è¦å­—æ®µï¼Œå¿…é¡»åŒ…å«: {required_keys}ï¼Œå®é™…æä¾›: {list(data_dict.keys())}"
        ratio=data_dict["ratio"]
        resolution=data_dict["resolution"]
        assert ratio in self.SUPPORTED_ASPECT_RATIOS, f"ä¸æ”¯æŒçš„æ¯”ä¾‹,æ”¯æŒæ¯”ä¾‹ä¸º{self.SUPPORTED_ASPECT_RATIOS}"
        assert resolution in self.SUPPORTED_RESOLUTION,f"ä¸æ”¯æŒçš„åˆ†è¾¨ç‡,æ”¯æŒåˆ†è¾¨ç‡ä¸º{self.SUPPORTED_RESOLUTION}"
        prompt=data_dict["prompt"]
        img_payload=[]
        for image_pil in data_dict["image_list"]:
            image_pil = Image.open(image_pil)
            image_base64, mime_type=encode_pil_to_base64(image_pil)
            img_payload.append({
                            "inline_data": {
                                "mime_type": mime_type,
                                "data": image_base64
                            }
                        })
        try:
            payload = {
                "contents": [{
                    "parts": [{"text": prompt}]+img_payload
                }]
            }

            if ratio:
                payload["generationConfig"] = {
                    "responseModalities": ["IMAGE"],
                    "imageConfig": {
                        "aspectRatio": ratio,
                        "image_size": resolution
                    }
                }

            print("ğŸ“¡ å‘é€è¯·æ±‚åˆ° Gemini API...")
            # å‘é€éæµå¼è¯·æ±‚
            response = requests.post(
                self.api_url,
                headers=self.headers,
                json=payload,
                timeout=120
            )
            
            print("âœ… APIè¯·æ±‚æˆåŠŸï¼Œæ­£åœ¨è§£æå“åº”...")
            
            # è§£æéæµå¼JSONå“åº”
            try:
                result = response.json()
                print("âœ… æˆåŠŸè§£æJSONå“åº”")
            except json.JSONDecodeError as e:
                return False, f"JSONè§£æå¤±è´¥: {str(e)}",None
            
            if "candidates" not in result or len(result["candidates"]) == 0:
                return False, "æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®", None

            candidate = result["candidates"][0]
            if "content" not in candidate or "parts" not in candidate["content"]:
                return False, "å“åº”æ ¼å¼é”™è¯¯",None

            parts = candidate["content"]["parts"]
            output_image_data = None

            for part in parts:
                if "inlineData" in part and "data" in part["inlineData"]:
                    output_image_data = part["inlineData"]["data"]
                    break

            if not output_image_data:
                return False, "æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®",None
            
            try:            
                pil_img=base64_to_image(output_image_data)
                return pil_img
            except Exception as e:
                raise ValueError(f"å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")
    
                
        except requests.exceptions.Timeout:
            raise RuntimeError("è¯·æ±‚è¶…æ—¶ï¼ˆ300ç§’ï¼‰")
        except requests.exceptions.ConnectionError as e:
            raise RuntimeError(f"è¿æ¥é”™è¯¯: {str(e)}")
        except Exception as e:
            raise ValueError(f"æœªçŸ¥é”™è¯¯: {str(e)}")



    def nano_text2image(self, data_dict) :
        required_keys = {"prompt", "ratio","resolution"}
        assert required_keys <= data_dict.keys(), \
            f"ç¼ºå°‘å¿…è¦å­—æ®µï¼Œå¿…é¡»åŒ…å«: {required_keys}ï¼Œå®é™…æä¾›: {list(data_dict.keys())}"
        ratio=data_dict["ratio"]
        assert ratio in self.SUPPORTED_ASPECT_RATIOS, f"ä¸æ”¯æŒçš„æ¯”ä¾‹,æ”¯æŒæ¯”ä¾‹ä¸º{self.SUPPORTED_ASPECT_RATIOS}"
        
        prompt="å¸®æˆ‘ç”Ÿæˆå›¾ç‰‡,å›¾ç‰‡æç¤ºè¯å¦‚ä¸‹: "+data_dict["prompt"]
        resolution=data_dict["resolution"]
        print("ğŸš€ å¼€å§‹ç”Ÿæˆå›¾ç‰‡...")
        print(f"æç¤ºè¯: {prompt}")

        try:
            # æ„å»ºè¯·æ±‚æ•°æ®
            payload = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }]
            }

            if ratio:
                payload["generationConfig"] = {
                    "responseModalities": ["IMAGE"],
                    "imageConfig": {
                        "aspectRatio": ratio,
                        "image_size": resolution
                    }
                }

            print("ğŸ“¡ å‘é€è¯·æ±‚åˆ° Gemini API...")
            # å‘é€éæµå¼è¯·æ±‚

            response = requests.post(
                self.api_url,
                headers=self.headers,
                json=payload,
                timeout=120
            )
            
            if response.status_code != 200:
                error_msg = f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
                try:
                    error_detail = response.json()
                    error_msg += f", é”™è¯¯è¯¦æƒ…: {error_detail}"
                except:
                    error_msg += f", å“åº”å†…å®¹: {response.text[:500]}"
                return False, error_msg,None
            
            print("âœ… APIè¯·æ±‚æˆåŠŸï¼Œæ­£åœ¨è§£æå“åº”...")
            
            # è§£æéæµå¼JSONå“åº”
            try:
                result = response.json()
                print("âœ… æˆåŠŸè§£æJSONå“åº”")
            except json.JSONDecodeError as e:
                return False, f"JSONè§£æå¤±è´¥: {str(e)}",None
            
            #æå–å›¾ç‰‡æ•°æ®
            if "candidates" not in result or len(result["candidates"]) == 0:
                return False, "æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®",None

            candidate = result["candidates"][0]
            if "content" not in candidate or "parts" not in candidate["content"]:
                return False, "å“åº”æ ¼å¼é”™è¯¯",None

            parts = candidate["content"]["parts"]
            image_data = None

            for part in parts:
                if "inlineData" in part and "data" in part["inlineData"]:
                    image_data = part["inlineData"]["data"]
                    break

            if not image_data:
                return False, "æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®",None
            try:            
                pil_img=base64_to_image(image_data)
                return pil_img
            except Exception as e:
                raise ValueError(f"å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")
                
        except requests.exceptions.Timeout:
            raise RuntimeError("è¯·æ±‚è¶…æ—¶ï¼ˆ300ç§’ï¼‰")
        except requests.exceptions.ConnectionError as e:
            raise RuntimeError(f"è¿æ¥é”™è¯¯: {str(e)}")
        except Exception as e:
            raise ValueError(f"æœªçŸ¥é”™è¯¯: {str(e)}")

    def _extract_image_from_base64(self,content: str) -> Tuple[bool, Optional[Image.Image], str]:
        """
        é«˜æ•ˆæå–base64å›¾ç‰‡å¹¶è¿”å›PIL Imageå¯¹è±¡
        
        Args:
            content: åŒ…å«å›¾ç‰‡æ•°æ®çš„å†…å®¹
            
        Returns:
            Tuple[æ˜¯å¦æˆåŠŸ, PIL Imageå¯¹è±¡(æˆ–None), æ¶ˆæ¯]
        """
        try:
            print(f"ğŸ“„ å†…å®¹é¢„è§ˆï¼ˆå‰200å­—ç¬¦ï¼‰: {content[:200]}")
            
            # åŒ¹é… base64 å›¾ç‰‡æ•°æ®
            base64_pattern = r'data:image/([^;]+);base64,([A-Za-z0-9+/=]+)'
            match = re.search(base64_pattern, content)
            
            if not match:
                print('âš ï¸  æœªæ‰¾åˆ°base64å›¾ç‰‡æ•°æ®')
                raise ValueError("No image founded!")
            
            image_format = match.group(1)
            b64_data = match.group(2)
            
            print(f'ğŸ¨ å›¾åƒæ ¼å¼: {image_format}')
            print(f'ğŸ“ Base64æ•°æ®é•¿åº¦: {len(b64_data)} å­—ç¬¦')
            
            # è§£ç  base64
            image_data = base64.b64decode(b64_data)
            
            if len(image_data) < 100:
                return False, None, "è§£ç åçš„å›¾ç‰‡æ•°æ®å¤ªå°ï¼Œå¯èƒ½æ— æ•ˆ"
            
            # ä½¿ç”¨ PIL è¯»å–å›¾åƒ
            image = Image.open(io.BytesIO(image_data))
            print(f'ğŸ–¼ï¸ å›¾ç‰‡åŠ è½½æˆåŠŸï¼Œå°ºå¯¸: {image.size}, æ¨¡å¼: {image.mode}')
            
            return True, image, f"æˆåŠŸæå–å›¾åƒ ({image_format})"
            
        except Exception as e:
            return False, None, f"å¤„ç†å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

    def nano_image_comprehension(self, data_dict,prompt):
        required_keys = {"image"}
        assert required_keys <= data_dict.keys(), \
            f"ç¼ºå°‘å¿…è¦å­—æ®µï¼Œå¿…é¡»åŒ…å«: {required_keys}ï¼Œå®é™…æä¾›: {list(data_dict.keys())}"
        im=data_dict["image"]
        im = Image.open(im)
        im_base64,_=encode_pil_to_base64(im)
        headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
        # Prepare payload - generated image first, then ground truth
        payload = {
            "model": "gemini-2.5-flash",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {"url": im_base64}
                        },
                    ]
                }
            ],
            "max_tokens": 5000
        }

        # Make API call
        response = requests.post(self.api_url_compre, headers=headers, json=payload, timeout=600)
        response.raise_for_status()

            
        # Extract response content
        response_data = response.json()
        content = response_data['choices'][0]['message']['content']
        
        print(content)
        return content

if __name__=="__main__":
    g = GeminiImageGenerator()
    # æè¿°æ€§æç¤ºè¯ï¼ˆæ ¹æ®éœ€è¦ä¿®æ”¹ï¼‰
    prompt = """You are a concise storyboard narrator focused on core scene and composition description. Based on the 1 vertically stitched image containing multiple storyboards (identified as Storyboard 1 to Storyboard N in top-to-bottom order, N = actual number), output ONLY a simple story background and concise composition descriptions for each shot. Strictly follow the JSON format below, with each "Image Composition" limited to ~100 words:
{"Simple Story Background": "1-2 sentences summarizing the basic story context (e.g., 'A girl searches for her lost cat in a suburban neighborhood on a sunny afternoon')","Storyboard_List": [{"Shot Number": 1,"Scene": "Specific location (e.g., front yard of a cottage, forest trail, downtown cafÃ©)","Image Composition": "Concise description of characters (appearance, posture), key props, framing (shot type: close-up/medium/long/wide), lighting, and core visual elements (max 100 words)","Emotional Tone": "Brief atmosphere (e.g., warm, tense, peaceful)"},{"Shot Number": N,"Scene": "Same as above","Image Composition": "Same as above (max 100 words)","Emotional Tone": "Same as above"}]}
Requirements
All fields are mandatory; no redundant content.
"Image Composition" focuses only on critical visual information (characters, framing, key props, lighting) â€“ no excessive details.
Strictly match the number/order of storyboards in the image (top-to-bottom numbering).
JSON format must be error-free, ready for direct use.
No extra text outside the JSON structure."""

    INPUT_DIR = "dataset/spotlight_sketch_cat/GT"
    OUTPUT_DIR = "dataset/spotlight_sketch_cat"
    RATIO = "16:9"
    # å¯¹è¾“å…¥æ–‡ä»¶å¤¹å†…çš„å›¾ç‰‡è¿›è¡Œæ’åºå¤„ç†

    output_path = os.path.join(OUTPUT_DIR, "spotlight_nano_comprehension_1203.txt")
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    input_files = sorted(
        fname for fname in os.listdir(INPUT_DIR)
        if os.path.isfile(os.path.join(INPUT_DIR, fname))
    )

    for idx, fname in tqdm(enumerate(input_files), total=len(input_files)):
        src_path = os.path.join(INPUT_DIR, fname)
        # è°ƒç”¨nano_image_comprehension
        # try:
        # pil_in = Image.open(src_path).convert("RGB")

        result = g.nano_image_comprehension({
            "image": src_path,
        },prompt)
        base_name = os.path.splitext(fname)[0]
        with open(output_path, "a", encoding="utf-8") as f:
            result = result.replace("\n", "")
            result = result.replace("```", "")
            result = result.replace("json", "")
            result = result.replace('"Simple Story Background"', f'"Image_Name": "{base_name}", "Simple Story Background"')

            f.write(result.strip("\n") + "\n")
        # except Exception as e:
        #     print(f"å¤„ç†æ–‡ä»¶ {fname} æ—¶å‡ºé”™: {e}")